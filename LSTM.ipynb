{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPw71DlGiRgfzsGFH/vEbe9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaa00/Text-generation-LSTM/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZsN-DRqTHvU"
      },
      "source": [
        "# **Text generation with LSTM** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZULmeEWTNU0"
      },
      "source": [
        "\n",
        "La premiere chose dont on a besoin c est d avoir un fichier text contenant des données enormes de mots afin d apprendre notre model de langage. Dans cet exemple nous allons utiliser des écrits de Nietzsche. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmBz74lUTOBT",
        "outputId": "bb4e5391-3690-4b34-89cc-42a87da5e88c"
      },
      "source": [
        "# loading libraries \n",
        "import keras\n",
        "import numpy as np\n",
        "#telecharger le fichier et le convertir en miniscules \n",
        "path = keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzWLuAyKYygu"
      },
      "source": [
        "Dans la partie qui suive nous allons extraire des sequences de longueur qui se chevauchent partiellement \"maxlen\" ,  les encoder \"one-hot\" et les emballer dans un \"3D Numpy array\" x de shape (sequences, maxlen, unique_characters)  , on prepare par la suite an array y contenant ce 'one hot encoded' qui viennent juste apres chaque sequence extraite. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6QPeYuVyy0",
        "outputId": "cdb0e727-38a0-4dac-c38e-2a1a01057437"
      },
      "source": [
        "# Longueur des sequences de caracteres extraites\n",
        "maxlen = 60\n",
        "# Nous echantillonnons une nouvelle sequence de caractere a chaque etape\n",
        "step = 3\n",
        "\n",
        "# Ceci contient nos sequences extraites \n",
        "sentences = []\n",
        "# ceci contient notre cible\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Number of sequences:', len(sentences))\n",
        "\n",
        "# liste des caracteres uniques dans le fichier \n",
        "chars = sorted(list(set(text)))\n",
        "print(chars)\n",
        "\n",
        "print('Unique characters:', len(chars))\n",
        "\n",
        "# un dictionnaire qui relie les caractères uniques a leurs indexes dans 'chars'\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# one-hot encode les caracteres into binary arrays \n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ä', 'æ', 'é', 'ë']\n",
            "Unique characters: 57\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahWrkX5DbdvU"
      },
      "source": [
        "# **Building the network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSMbggDJb_n9"
      },
      "source": [
        "Notre réseau est une LSTM couche unique suivie d un Dense classificateur et d un softmax sur tous les caracteres possibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDS_XYE-bE3c"
      },
      "source": [
        "from keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lqn23fNoBIk"
      },
      "source": [
        "# **Training the language model and sampling from it**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbZNgvaWoYwk"
      },
      "source": [
        " \"\"     1 Draw from the model a probability distribution for the next character, given the generated text available so far.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKu_ckw0ojua"
      },
      "source": [
        "2 Reweight the distribution to a certain temperature.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmmn6KvWon1b"
      },
      "source": [
        "3 Sample the next character at random according to the reweighted distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSIZ5QPkoqSz"
      },
      "source": [
        "4 Add the new character at the end of the available text. \"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvP6tvq9nr2U"
      },
      "source": [
        "# c'est le code que nous utilisons pour reponderer la distribution de la probabilite originale sortant du modele, \n",
        "#et en tirer un index de caractere  \"sampling function\":\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzZcPsg6pSb8"
      },
      "source": [
        "Par la suite nous utilisions une boucle où nous entraînons et generons le texte a plusieurs reprises. Nous commençons a generer du texte en utilisant une plage de temperatures differentes apres chaque epoque. Cela nous permet de voir comment le texte generé evolue lorsque le modele commence a converger, ainsi que l'impact de la temperature dans la strategie d'echantillonnage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6uCjxrXpQv8",
        "outputId": "7f1e9515-aa61-40f1-9c10-6732a0e090b4"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "# Ici nous pouvons voir le contenu de chaque epochs et comment ca fonctionne (on a 5 epochs for run )\n",
        "for epoch in range(1, 5):\n",
        "    print('epoch', epoch)\n",
        "    # Fit the model pour 1 epoch on the \"training data\"  disponible\n",
        "    model.fit(x, y,batch_size=128, epochs=1)\n",
        "\n",
        "    # selectionner une partie du text au hasard \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated_text = text[start_index: start_index + maxlen]\n",
        "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('------ temperature:', temperature)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # on genere 400 caracteres \n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "1565/1565 [==============================] - 270s 172ms/step - loss: 1.4351\n",
            "--- Generating with seed: \"ditional\n",
            "estimates of things, as the most desirable of all s\"\n",
            "------ temperature: 0.2\n",
            "ditional\n",
            "estimates of things, as the most desirable of all seek on the sensible of the subtle and the subjection of the spirit and all the world and the sension of the spirit and the suppose of the present and some the such a subtle the striff the such as the spirit and the stronger of the subtle the strength the conscience, and the stronger of the superior of the same and the subtle that the superior the the subjection of the present the sension of the pr\n",
            "------ temperature: 0.5\n",
            "rior the the subjection of the present the sension of the problem for the ething and one and the master of such an the present, the conscience, it really and the person to the soul and what the most for the sension of the contempt the lack of the heart and sympathy of the conscience,\n",
            "and the man and the profound and for which the philosophers and suspaticing must for an and not to be such a profound the most sacrification of the self-sanction of the nation\n",
            "------ temperature: 1.0\n",
            "nd the most sacrification of the self-sanction of the national schoisinence is be covide the gerveen repronate decived some the way.=--just question, we must pleasure-lariof', whylent of the world. i\n",
            "believe at by\n",
            "ale;,\"\n",
            "and had pustor of que strust to judg of man be tangeistode that we value so\n",
            "being, but \"wholities and day\n",
            "actions, where woman, and eye the in . the through therr\"--it has not\n",
            "is this was ideass of\n",
            "his morals general, one he may no yet thi\n",
            "------ temperature: 1.2\n",
            "this was ideass of\n",
            "his morals general, one he may no yet thistige definitude, adavining owowily appaised of\n",
            "the opinionble of bad;\n",
            "but the culteming consciencus this, too lidelured in afopen of out brings bitway, his lachponed, stitudityed, ha suffer anivery, them creathred that\n",
            "wondempo, a dehining thus tneiseness which a it he lets the whole rela the knew is . these rust he, addand,\n",
            "the obt \"new, ale on theolity is ushation of \n",
            "lowe, which severy it wear\n",
            "epoch 2\n",
            "1565/1565 [==============================] - 267s 170ms/step - loss: 1.4173\n",
            "--- Generating with seed: \"the un-greek in christianity.=--the greeks did not look upon\"\n",
            "------ temperature: 0.2\n",
            "the un-greek in christianity.=--the greeks did not look upon the sense of the look that the interminess of the fact of the formerly, and the world and the state of the self-specially the will to the world and something the profound of the most such an interminess, there is not the belief and the self-see for the most self-and sense of the profound that the self-profound and something that the self-state of the conscious of the sense of the thought the stru\n",
            "------ temperature: 0.5\n",
            "-state of the conscious of the sense of the thought the structure of the most permar of the has not a metapes to the be formelt of the\n",
            "fact that any one that the dimonation of the most surerance of the work, be in the fact of europe, it is resist, the eworm, and more to the things of the man\" halty and self-conceal every superies, in life and to be a moral form of the will of the most same conversted\n",
            "different and that are morality of the world in enemy of\n",
            "------ temperature: 1.0\n",
            "ted\n",
            "different and that are morality of the world in enemy of things every\n",
            "been them--if there are how he worth is an espasides?, our are\n",
            "belity germanivers uplation of knowling, for a guilts be ef to a mans, however\n",
            "beyond the german \"ma, if a dea life. on      and presentimenishing into enumaning, he that enility of an an\n",
            "eduation who do\n",
            "moken\n",
            "vice have phantersual anding fineeiny, usal of physisia proud met out\", at alther! there is they would both\", amo\n",
            "------ temperature: 1.2\n",
            "ia proud met out\", at alther! there is they would both\", amordingbantly intefpeaited.\n",
            "\n",
            "er avertleset, foregoment and no-lacks he bate one cawake, truhor viality of very noble,--pertoy.\n",
            "\n",
            "ester plopiate of \"que of philosophy or long men, them sustamm erily ., such\n",
            "cleffers bevore youn, conflimeness,\n",
            "\"suremitivan\n",
            "tempoutipow of\n",
            "him.\n",
            "\n",
            "\n",
            "\n",
            "le, and anyshere much of lvust philosopher of. to belonce, the itntimed heaven, but the toots) has morroight\n",
            "to the imperual \n",
            "epoch 3\n",
            "1565/1565 [==============================] - 268s 171ms/step - loss: 1.4067\n",
            "--- Generating with seed: \"ing egoisms, which strive with one another \"for sun and ligh\"\n",
            "------ temperature: 0.2\n",
            "ing egoisms, which strive with one another \"for sun and light of the sense in the fact to the most as the sense of the sense of the present the sense of the sense of the present the discoversed to the strength and such as the sense of the present and the sense of the present the sense in the same to the same and the consequently to the sense of the sense of the sense of the trangderation of the same to the sense of the same and such as the sense of the pre\n",
            "------ temperature: 0.5\n",
            "me to the sense of the same and such as the sense of the present the right to the will account to the great all boded to the world on a past and more to the the nor as one of the day as the words because the consequently between that it is the of the uneprises to be case to a man of this sense: as the consequently soul of the\n",
            "taste of the present and to\n",
            "in the transfulding the interpretation of the present and all the delicate most consequently and compari\n",
            "------ temperature: 1.0\n",
            "e present and all the delicate most consequently and comparis it hatrer, that whole yet we one\n",
            "a goved origives\n",
            "foo example: only little\n",
            "prutestign \"the\n",
            "best that at least and pistois! he moral mepimacation of usan, in regard and affecitudes and rextens, best soul. in the destances\" that her surestudes\n",
            "only called infariofy, but this question alood present, even in of\n",
            "the conourrelvess modes in his colcerding, the\n",
            "\"age, and impulses the greatness andmarity\n",
            "------ temperature: 1.2\n",
            "s colcerding, the\n",
            "\"age, and impulses the greatness andmarity and perhaps, the\n",
            "bedefect. not bernaintuiys pains, is will\n",
            "addisses, he right opinionsly rockstrone, bespeary\n",
            "has jehhar henle go drange, how indratidiedaun; it the \n",
            "birdup tike to him)ly happinessions deeps!--things mamire. it\n",
            "race,\n",
            "in expression of time? a meph, done, an yet the worss swatt of properined\n",
            "and surpeepkbatfy. if i 'negr of the\n",
            "inle? if they connection, injurention, bevolt.wing rel\n",
            "epoch 4\n",
            "1565/1565 [==============================] - 270s 173ms/step - loss: 1.3951\n",
            "--- Generating with seed: \"a long life lived naturally, so\n",
            "oppressed by a weight of sin\"\n",
            "------ temperature: 0.2\n",
            "a long life lived naturally, so\n",
            "oppressed by a weight of since of the most strokes to the consciousness of the home to the sense of the therefore, and there is a stronger and thereby the problem of the strokes and the problem of the history of the same thereby an one will the thereby the such an and the best and interpretation of the same that they are thereby the sense of the proved they are not they are not the sense of the spirit and all the former to t\n",
            "------ temperature: 0.5\n",
            "they are not the sense of the spirit and all the former to the problem and hered to be one is a probably non the spirit and some the worthy in the subtle to the discome has he has hitherto some the origin. and which seedly of the therefore, and they has been our orignt to say, and an interrogation as\n",
            "into the most commands, according to the form they are confact, the great our something of conscious and intellectual therefore, there is not be herevols and \n",
            "------ temperature: 1.0\n",
            "us and intellectual therefore, there is not be herevols and church and humanal actionsha\n",
            "grouty and\n",
            "spirits him, know an,\n",
            "that and present, man,\" those divined, and into birdpor mefter rusting of virtues\n",
            "and wast ourselves situral and one of sigh to be speak for an at\n",
            "pion to the consciousness of this is and infurior with their good okendlessal w  hatherlans that they.\n",
            "\n",
            "hone of a only their contrast home in an immensegy is perhine to healthed to be uncould\n",
            "------ temperature: 1.2\n",
            "st home in an immensegy is perhine to healthed to be uncould stageous wsy\n",
            "trans his encessible ground modifies feousnd, his egoisive right into seren occuuse, and repends must--who europe,\n",
            "pce; thereby frol world suh\n",
            "that\n",
            "with old modean\n",
            "cexaredly at littless in the wal either\n",
            "be home man, i\"\n",
            "possessimally to possessed in unbeal, it: su; \"pathed. with arth cincu, to will phollicbly, but\n",
            "aromes\n",
            "long and consciousness\" undiaw frioth, importancal strok. and w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGkkwEoPqOBN"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61uGUfxSzNgM"
      },
      "source": [
        "*Une température basse entraîne un texte  répétitif et prévisible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VBItJNj-klY"
      },
      "source": [
        "*Une température elevée entraine un texte plus intéressant, surprenant; il peut parfois inventer des mots complètement nouveaux. La structure locale commence à se décomposer et la plupart des mots ressemblent à des chaînes semi-aléatoires de caractères."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwGhjilECQLJ"
      },
      "source": [
        "=> 0,5 est la température la plus intéressante pour la génération du texte "
      ]
    }
  ]
}